{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084a3a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Binura'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee70746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\n"
     ]
    }
   ],
   "source": [
    "cd C:\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a3fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Binura\\MLOM\\Cat&Dog Dataset\n"
     ]
    }
   ],
   "source": [
    "cd Cat&Dog Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aafaf0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accquire data\n",
    "train_path = 'Training_data'\n",
    "valid_path = 'Testing_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a25af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model\n",
    "import tensorflow as tf\n",
    "from scipy import special\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    #Note the input shape is the desired size of the image 300*300 with 3 bytes color\n",
    "    #This is the first convolution\n",
    "    tf.keras.layers.Conv2D(filters=16,kernel_size=3,activation='relu',input_shape=(300,300,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    #The second convolution\n",
    "    tf.keras.layers.Conv2D(filters=16,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    #The third convolution\n",
    "    tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    #The fourth convolution\n",
    "    tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    #Flattern the results to feed into a CNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    #512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    \n",
    "    #Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('Cat') and 1 for the other('Dog')\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1cbd3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 149, 149, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 147, 147, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 73, 73, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 71, 71, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 35, 35, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 33, 33, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               8389120   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,415,537\n",
      "Trainable params: 8,415,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#getting the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6e3e297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Binura\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#compiling the model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=RMSprop(lr=0.001),#learning rate as step size\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d271abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 633 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#train the model from the generators\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#All train images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#Flow training images in batches of 128  using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_path, #This is the source directory for the training images\n",
    "                                                   target_size=(300,300),#All images will be resized to 150*150\n",
    "                                                    batch_size=32,\n",
    "                                                    #Since we use binary_crossentropy loss, we need binary labels \n",
    "                                                    class_mode='binary')\n",
    "\n",
    "#All test images will be rescaled 1./255\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#apply predefined specification to test the dataset\n",
    "test_set = test_datagen.flow_from_directory(valid_path,\n",
    "                                            target_size=(300,300),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14077f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 3s 342ms/step - loss: 0.7197 - accuracy: 0.5863 - val_loss: 0.6560 - val_accuracy: 0.5350\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 3s 373ms/step - loss: 0.6148 - accuracy: 0.6992 - val_loss: 1.0722 - val_accuracy: 0.5000\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 0.5739 - accuracy: 0.7108 - val_loss: 0.9323 - val_accuracy: 0.5000\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 3s 368ms/step - loss: 0.6447 - accuracy: 0.6562 - val_loss: 0.6217 - val_accuracy: 0.6750\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 3s 338ms/step - loss: 0.5577 - accuracy: 0.7269 - val_loss: 0.5959 - val_accuracy: 0.7000\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 0.5400 - accuracy: 0.7309 - val_loss: 0.7515 - val_accuracy: 0.5750\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.5799 - accuracy: 0.7031 - val_loss: 0.5991 - val_accuracy: 0.7000\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.4921 - accuracy: 0.8008 - val_loss: 0.7788 - val_accuracy: 0.5550\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.4101 - accuracy: 0.8008 - val_loss: 0.9153 - val_accuracy: 0.5800\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.5252 - accuracy: 0.7344 - val_loss: 0.6631 - val_accuracy: 0.6450\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 3s 316ms/step - loss: 0.4329 - accuracy: 0.7891 - val_loss: 0.6753 - val_accuracy: 0.6350\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 3s 356ms/step - loss: 0.3947 - accuracy: 0.8281 - val_loss: 0.6842 - val_accuracy: 0.6600\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 3s 366ms/step - loss: 0.4140 - accuracy: 0.8164 - val_loss: 0.8452 - val_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 0.3686 - accuracy: 0.8477 - val_loss: 0.6027 - val_accuracy: 0.7050\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 3s 366ms/step - loss: 0.2551 - accuracy: 0.8956 - val_loss: 0.7482 - val_accuracy: 0.6750\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 0.3054 - accuracy: 0.8516 - val_loss: 0.9198 - val_accuracy: 0.5850\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 0.3988 - accuracy: 0.7952 - val_loss: 0.7833 - val_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 3s 368ms/step - loss: 0.2892 - accuracy: 0.9102 - val_loss: 0.8577 - val_accuracy: 0.6850\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 3s 363ms/step - loss: 0.2852 - accuracy: 0.8876 - val_loss: 0.7149 - val_accuracy: 0.6350\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.2721 - accuracy: 0.8795 - val_loss: 1.3491 - val_accuracy: 0.5950\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 0.2282 - accuracy: 0.8984 - val_loss: 0.9211 - val_accuracy: 0.6400\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.2462 - accuracy: 0.8876 - val_loss: 0.9629 - val_accuracy: 0.6650\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.1734 - accuracy: 0.9237 - val_loss: 0.9295 - val_accuracy: 0.6300\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 0.1526 - accuracy: 0.9336 - val_loss: 0.8768 - val_accuracy: 0.6450\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 3s 363ms/step - loss: 0.2749 - accuracy: 0.8711 - val_loss: 0.8829 - val_accuracy: 0.6800\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 0.1522 - accuracy: 0.9531 - val_loss: 0.9316 - val_accuracy: 0.6350\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 0.1211 - accuracy: 0.9598 - val_loss: 1.0088 - val_accuracy: 0.6550\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 0.1292 - accuracy: 0.9648 - val_loss: 1.0101 - val_accuracy: 0.6500\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 3s 343ms/step - loss: 0.1508 - accuracy: 0.9297 - val_loss: 0.9591 - val_accuracy: 0.6550\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.0743 - accuracy: 0.9839 - val_loss: 1.3000 - val_accuracy: 0.6200\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 0.0651 - accuracy: 0.9839 - val_loss: 1.6940 - val_accuracy: 0.6100\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 0.1227 - accuracy: 0.9598 - val_loss: 1.4741 - val_accuracy: 0.6350\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.0389 - accuracy: 0.9960 - val_loss: 1.6184 - val_accuracy: 0.5950\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 3s 320ms/step - loss: 0.0221 - accuracy: 0.9960 - val_loss: 1.6820 - val_accuracy: 0.6450\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 3s 337ms/step - loss: 1.0072 - accuracy: 0.8353 - val_loss: 1.1051 - val_accuracy: 0.6400\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 0.0434 - accuracy: 0.9960 - val_loss: 1.2323 - val_accuracy: 0.6650\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.0330 - accuracy: 0.9961 - val_loss: 1.3683 - val_accuracy: 0.6400\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 1.5672 - val_accuracy: 0.6150\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 0.0608 - accuracy: 0.9799 - val_loss: 1.3756 - val_accuracy: 0.6250\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 3s 321ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.5310 - val_accuracy: 0.6350\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.3523 - accuracy: 0.9141 - val_loss: 1.8195 - val_accuracy: 0.5900\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 3s 338ms/step - loss: 0.0761 - accuracy: 0.9727 - val_loss: 1.1342 - val_accuracy: 0.6550\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.6750\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 1.3858 - val_accuracy: 0.6550\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.5347 - val_accuracy: 0.6650\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 0.0605 - accuracy: 0.9805 - val_loss: 4.2622 - val_accuracy: 0.5250\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.4977 - accuracy: 0.8867 - val_loss: 1.1329 - val_accuracy: 0.6600\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 3s 318ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.2443 - val_accuracy: 0.6650\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.3354 - val_accuracy: 0.6700\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.4043 - val_accuracy: 0.6600\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5292 - val_accuracy: 0.6700\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.9827 - val_accuracy: 0.6650\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 1.0234 - accuracy: 0.8633 - val_loss: 1.2512 - val_accuracy: 0.6700\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.3243 - val_accuracy: 0.6750\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3524 - val_accuracy: 0.6850\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.4354 - val_accuracy: 0.7000\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5117 - val_accuracy: 0.7050\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 326ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.7400 - val_accuracy: 0.6550\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8513 - val_accuracy: 0.6700\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9619 - val_accuracy: 0.6900\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1254 - val_accuracy: 0.6300\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 0.6778 - accuracy: 0.9258 - val_loss: 1.3414 - val_accuracy: 0.7050\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.4449 - val_accuracy: 0.6950\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5029 - val_accuracy: 0.6950\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6228 - val_accuracy: 0.6950\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7175 - val_accuracy: 0.6900\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 6.9252e-04 - accuracy: 1.0000 - val_loss: 1.7961 - val_accuracy: 0.6850\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 6.3275e-04 - accuracy: 1.0000 - val_loss: 1.8006 - val_accuracy: 0.7050\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 3s 335ms/step - loss: 4.1205e-04 - accuracy: 1.0000 - val_loss: 2.0858 - val_accuracy: 0.6850\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 3s 314ms/step - loss: 2.8534e-04 - accuracy: 1.0000 - val_loss: 2.0435 - val_accuracy: 0.6850\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 1.2838e-04 - accuracy: 1.0000 - val_loss: 2.0640 - val_accuracy: 0.6950\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 5.8196e-05 - accuracy: 1.0000 - val_loss: 2.2213 - val_accuracy: 0.7050\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 6.4839e-05 - accuracy: 1.0000 - val_loss: 2.3809 - val_accuracy: 0.6800\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 3s 321ms/step - loss: 5.1152e-05 - accuracy: 1.0000 - val_loss: 2.2734 - val_accuracy: 0.6750\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 6.9053e-05 - accuracy: 1.0000 - val_loss: 4.1553 - val_accuracy: 0.6450\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 3s 319ms/step - loss: 1.2813 - accuracy: 0.8672 - val_loss: 1.7054 - val_accuracy: 0.6850\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.7499 - val_accuracy: 0.6750\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7942 - val_accuracy: 0.6700\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8554 - val_accuracy: 0.6700\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9490 - val_accuracy: 0.6750\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 6.1421e-04 - accuracy: 1.0000 - val_loss: 2.0279 - val_accuracy: 0.6700\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 9.9398e-04 - accuracy: 1.0000 - val_loss: 2.3095 - val_accuracy: 0.7000\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 3s 366ms/step - loss: 8.5783e-04 - accuracy: 1.0000 - val_loss: 2.1340 - val_accuracy: 0.6750\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 3s 363ms/step - loss: 4.8599e-04 - accuracy: 1.0000 - val_loss: 2.1730 - val_accuracy: 0.6950\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 3s 366ms/step - loss: 1.7593e-04 - accuracy: 1.0000 - val_loss: 2.1788 - val_accuracy: 0.6900\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 1.1672e-04 - accuracy: 1.0000 - val_loss: 2.2961 - val_accuracy: 0.6900\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 7.5417e-05 - accuracy: 1.0000 - val_loss: 2.4646 - val_accuracy: 0.6750\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 3s 334ms/step - loss: 5.7125e-05 - accuracy: 1.0000 - val_loss: 2.4125 - val_accuracy: 0.6850\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 3s 353ms/step - loss: 5.8638e-05 - accuracy: 1.0000 - val_loss: 2.6376 - val_accuracy: 0.6900\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 2.1922e-05 - accuracy: 1.0000 - val_loss: 2.6720 - val_accuracy: 0.6850\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 1.1981e-05 - accuracy: 1.0000 - val_loss: 2.7084 - val_accuracy: 0.6900\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 3s 338ms/step - loss: 1.2796e-05 - accuracy: 1.0000 - val_loss: 2.7278 - val_accuracy: 0.6850\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 7.1628e-06 - accuracy: 1.0000 - val_loss: 2.7891 - val_accuracy: 0.6850\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 3s 315ms/step - loss: 3.9292e-06 - accuracy: 1.0000 - val_loss: 2.8967 - val_accuracy: 0.6950\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 4.4417e-06 - accuracy: 1.0000 - val_loss: 3.0327 - val_accuracy: 0.6800\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 3s 320ms/step - loss: 1.8719e-06 - accuracy: 1.0000 - val_loss: 3.1981 - val_accuracy: 0.6800\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 1.4278 - accuracy: 0.9237 - val_loss: 1.8274 - val_accuracy: 0.6400\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7618 - val_accuracy: 0.6650\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 9.9434e-04 - accuracy: 1.0000 - val_loss: 1.7958 - val_accuracy: 0.6500\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 7.5268e-04 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.6600\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 6.9307e-04 - accuracy: 1.0000 - val_loss: 1.8568 - val_accuracy: 0.6750\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 4.1286e-04 - accuracy: 1.0000 - val_loss: 1.8747 - val_accuracy: 0.6850\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 2.8827e-04 - accuracy: 1.0000 - val_loss: 1.9303 - val_accuracy: 0.6900\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 1.6669e-04 - accuracy: 1.0000 - val_loss: 1.9687 - val_accuracy: 0.6950\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 1.7665e-04 - accuracy: 1.0000 - val_loss: 2.0397 - val_accuracy: 0.6900\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 7.1220e-05 - accuracy: 1.0000 - val_loss: 2.0935 - val_accuracy: 0.6850\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 3s 337ms/step - loss: 8.7047e-05 - accuracy: 1.0000 - val_loss: 2.1786 - val_accuracy: 0.6900\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 5.9817e-05 - accuracy: 1.0000 - val_loss: 2.2723 - val_accuracy: 0.6850\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 3.3738e-05 - accuracy: 1.0000 - val_loss: 2.3007 - val_accuracy: 0.6800\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 3s 336ms/step - loss: 0.0861 - accuracy: 0.9805 - val_loss: 2.7381 - val_accuracy: 0.5550\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 0.3903 - accuracy: 0.9062 - val_loss: 1.7803 - val_accuracy: 0.6450\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 3s 355ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.6550\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 3s 362ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.9104 - val_accuracy: 0.6500\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 365ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0087 - val_accuracy: 0.6700\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 5.7983e-04 - accuracy: 1.0000 - val_loss: 2.0780 - val_accuracy: 0.6850\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 3.6049e-04 - accuracy: 1.0000 - val_loss: 2.1262 - val_accuracy: 0.6800\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 2.6338e-04 - accuracy: 1.0000 - val_loss: 2.2541 - val_accuracy: 0.6900\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 1.3305e-04 - accuracy: 1.0000 - val_loss: 2.3388 - val_accuracy: 0.6950\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 9.1580e-05 - accuracy: 1.0000 - val_loss: 2.3331 - val_accuracy: 0.6850\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 6.9274e-05 - accuracy: 1.0000 - val_loss: 2.4654 - val_accuracy: 0.7000\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 3.3540e-05 - accuracy: 1.0000 - val_loss: 2.5209 - val_accuracy: 0.7000\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 2.4262e-05 - accuracy: 1.0000 - val_loss: 2.5727 - val_accuracy: 0.6950\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 1.4907e-05 - accuracy: 1.0000 - val_loss: 2.6040 - val_accuracy: 0.7150\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.0057 - accuracy: 0.9961 - val_loss: 17.5960 - val_accuracy: 0.4950\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 0.9487 - accuracy: 0.9336 - val_loss: 1.8730 - val_accuracy: 0.6750\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.9280 - val_accuracy: 0.6850\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.9330 - val_accuracy: 0.7050\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0688 - val_accuracy: 0.7100\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1323 - val_accuracy: 0.6950\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 3.8375e-04 - accuracy: 1.0000 - val_loss: 2.1381 - val_accuracy: 0.6950\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 1.7165e-04 - accuracy: 1.0000 - val_loss: 2.1745 - val_accuracy: 0.7000\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 1.1726e-04 - accuracy: 1.0000 - val_loss: 2.2218 - val_accuracy: 0.6950\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 9.5551e-05 - accuracy: 1.0000 - val_loss: 2.2634 - val_accuracy: 0.6950\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 7.5026e-05 - accuracy: 1.0000 - val_loss: 2.3357 - val_accuracy: 0.7000\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 7.2879e-05 - accuracy: 1.0000 - val_loss: 2.4845 - val_accuracy: 0.7000\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 4.1110e-05 - accuracy: 1.0000 - val_loss: 2.5410 - val_accuracy: 0.6950\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 3s 377ms/step - loss: 1.8242e-05 - accuracy: 1.0000 - val_loss: 2.6168 - val_accuracy: 0.7100\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 3s 337ms/step - loss: 1.2469e-05 - accuracy: 1.0000 - val_loss: 2.6801 - val_accuracy: 0.6950\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 8.7833e-06 - accuracy: 1.0000 - val_loss: 2.7408 - val_accuracy: 0.7000\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 7.6743e-06 - accuracy: 1.0000 - val_loss: 2.7957 - val_accuracy: 0.7000\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 6.9024e-06 - accuracy: 1.0000 - val_loss: 2.9930 - val_accuracy: 0.7000\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 3s 378ms/step - loss: 3.1056e-06 - accuracy: 1.0000 - val_loss: 3.0145 - val_accuracy: 0.7050\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 2.0675e-06 - accuracy: 1.0000 - val_loss: 3.0106 - val_accuracy: 0.7150\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 1.4459e-06 - accuracy: 1.0000 - val_loss: 3.0901 - val_accuracy: 0.7050\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 3s 320ms/step - loss: 1.1222e-06 - accuracy: 1.0000 - val_loss: 3.1956 - val_accuracy: 0.7050\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 7.6313e-07 - accuracy: 1.0000 - val_loss: 3.2690 - val_accuracy: 0.6950\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 3s 314ms/step - loss: 3.8875e-07 - accuracy: 1.0000 - val_loss: 3.3657 - val_accuracy: 0.7150\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 4.2748e-07 - accuracy: 1.0000 - val_loss: 3.5237 - val_accuracy: 0.6900\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 2.3794e-07 - accuracy: 1.0000 - val_loss: 3.6138 - val_accuracy: 0.7050\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 2.0203e-07 - accuracy: 1.0000 - val_loss: 3.6777 - val_accuracy: 0.6900\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 9.9651e-08 - accuracy: 1.0000 - val_loss: 3.7789 - val_accuracy: 0.7050\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 7.5643e-08 - accuracy: 1.0000 - val_loss: 3.8853 - val_accuracy: 0.6900\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 5.3141e-08 - accuracy: 1.0000 - val_loss: 3.9909 - val_accuracy: 0.6950\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 2.8871e-08 - accuracy: 1.0000 - val_loss: 4.0641 - val_accuracy: 0.6800\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.0047 - accuracy: 0.9961 - val_loss: 19.8546 - val_accuracy: 0.5150\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.8512 - accuracy: 0.9453 - val_loss: 1.8310 - val_accuracy: 0.6700\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 3s 334ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.1119 - val_accuracy: 0.7050\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.2108 - val_accuracy: 0.7000\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.2901 - val_accuracy: 0.7000\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 2.8343e-04 - accuracy: 1.0000 - val_loss: 2.3492 - val_accuracy: 0.6950\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 2.5640e-04 - accuracy: 1.0000 - val_loss: 2.3866 - val_accuracy: 0.7050\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 3.4350e-04 - accuracy: 1.0000 - val_loss: 2.4467 - val_accuracy: 0.7000\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 3.5808e-04 - accuracy: 1.0000 - val_loss: 3.1223 - val_accuracy: 0.6550\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 2.6245e-04 - accuracy: 1.0000 - val_loss: 2.7641 - val_accuracy: 0.6800\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 3s 320ms/step - loss: 7.9594e-05 - accuracy: 1.0000 - val_loss: 3.1885 - val_accuracy: 0.6600\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 2.9087e-05 - accuracy: 1.0000 - val_loss: 2.9922 - val_accuracy: 0.6850\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 8.5823e-06 - accuracy: 1.0000 - val_loss: 2.9889 - val_accuracy: 0.6750\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 8.4094e-06 - accuracy: 1.0000 - val_loss: 3.0496 - val_accuracy: 0.6750\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 3s 349ms/step - loss: 1.0416e-05 - accuracy: 1.0000 - val_loss: 3.0839 - val_accuracy: 0.6850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/1000\n",
      "8/8 [==============================] - 3s 369ms/step - loss: 4.1512e-06 - accuracy: 1.0000 - val_loss: 3.1471 - val_accuracy: 0.6900\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 3s 347ms/step - loss: 2.7879e-06 - accuracy: 1.0000 - val_loss: 3.1760 - val_accuracy: 0.6900\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 1.6852e-06 - accuracy: 1.0000 - val_loss: 3.2438 - val_accuracy: 0.6950\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 1.3555e-06 - accuracy: 1.0000 - val_loss: 3.3030 - val_accuracy: 0.6900\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 3s 344ms/step - loss: 9.7186e-07 - accuracy: 1.0000 - val_loss: 3.3461 - val_accuracy: 0.6900\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 3s 366ms/step - loss: 6.1048e-07 - accuracy: 1.0000 - val_loss: 3.3899 - val_accuracy: 0.6850\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 4.4859e-07 - accuracy: 1.0000 - val_loss: 3.4890 - val_accuracy: 0.6900\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 4.0186e-07 - accuracy: 1.0000 - val_loss: 3.5098 - val_accuracy: 0.6900\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 2.9383e-07 - accuracy: 1.0000 - val_loss: 3.5855 - val_accuracy: 0.6900\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 3s 369ms/step - loss: 0.9585 - accuracy: 0.9141 - val_loss: 2.6403 - val_accuracy: 0.6600\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 2.6646 - val_accuracy: 0.6700\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7334 - val_accuracy: 0.6800\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 8.6151e-04 - accuracy: 1.0000 - val_loss: 2.7767 - val_accuracy: 0.6750\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 3s 335ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9568 - val_accuracy: 0.6750\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 6.2537e-04 - accuracy: 1.0000 - val_loss: 3.0811 - val_accuracy: 0.6700\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 4.2061e-04 - accuracy: 1.0000 - val_loss: 2.8659 - val_accuracy: 0.6850\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 1.4481e-04 - accuracy: 1.0000 - val_loss: 2.8836 - val_accuracy: 0.6950\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 1.2421e-04 - accuracy: 1.0000 - val_loss: 2.9805 - val_accuracy: 0.6950\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 1.2864e-04 - accuracy: 1.0000 - val_loss: 3.1101 - val_accuracy: 0.6950\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 3s 334ms/step - loss: 3.0258e-05 - accuracy: 1.0000 - val_loss: 3.1601 - val_accuracy: 0.6950\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 3.2651e-05 - accuracy: 1.0000 - val_loss: 3.1680 - val_accuracy: 0.7000\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 3s 339ms/step - loss: 2.2397e-05 - accuracy: 1.0000 - val_loss: 3.2504 - val_accuracy: 0.7000\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 1.1969e-05 - accuracy: 1.0000 - val_loss: 3.3172 - val_accuracy: 0.7000\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 8.2682e-06 - accuracy: 1.0000 - val_loss: 3.3848 - val_accuracy: 0.7000\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 1.5455e-05 - accuracy: 1.0000 - val_loss: 3.4168 - val_accuracy: 0.7000\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 3.6043e-06 - accuracy: 1.0000 - val_loss: 3.4334 - val_accuracy: 0.6950\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 5.8696e-06 - accuracy: 1.0000 - val_loss: 3.5302 - val_accuracy: 0.7000\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 1.0468e-06 - accuracy: 1.0000 - val_loss: 3.5412 - val_accuracy: 0.7000\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 1.2056e-06 - accuracy: 1.0000 - val_loss: 3.6423 - val_accuracy: 0.7000\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 7.9089e-07 - accuracy: 1.0000 - val_loss: 3.7089 - val_accuracy: 0.7050\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 4.2841e-07 - accuracy: 1.0000 - val_loss: 3.8000 - val_accuracy: 0.7050\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 1.9964e-07 - accuracy: 1.0000 - val_loss: 3.8459 - val_accuracy: 0.7050\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 1.5087e-07 - accuracy: 1.0000 - val_loss: 3.9032 - val_accuracy: 0.7000\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 2.4401e-07 - accuracy: 1.0000 - val_loss: 4.0149 - val_accuracy: 0.7050\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 1.1316e-07 - accuracy: 1.0000 - val_loss: 4.0529 - val_accuracy: 0.6950\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 3s 345ms/step - loss: 9.6857e-08 - accuracy: 1.0000 - val_loss: 4.1568 - val_accuracy: 0.6950\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 2.3097e-07 - accuracy: 1.0000 - val_loss: 4.1238 - val_accuracy: 0.6950\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 3.0804e-05 - accuracy: 1.0000 - val_loss: 6.4639 - val_accuracy: 0.5850\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 1.1161 - accuracy: 0.9297 - val_loss: 3.2934 - val_accuracy: 0.6600\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 4.0330e-04 - accuracy: 1.0000 - val_loss: 3.3005 - val_accuracy: 0.6600\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 7.1705e-04 - accuracy: 1.0000 - val_loss: 3.2307 - val_accuracy: 0.6650\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 4.0139e-04 - accuracy: 1.0000 - val_loss: 3.2765 - val_accuracy: 0.6550\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 1.7786e-04 - accuracy: 1.0000 - val_loss: 3.2876 - val_accuracy: 0.6550\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 7.9018e-05 - accuracy: 1.0000 - val_loss: 3.3290 - val_accuracy: 0.6550\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 6.4884e-05 - accuracy: 1.0000 - val_loss: 3.3592 - val_accuracy: 0.6550\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 4.7601e-05 - accuracy: 1.0000 - val_loss: 3.4068 - val_accuracy: 0.6550\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 2.6877e-05 - accuracy: 1.0000 - val_loss: 3.4281 - val_accuracy: 0.6550\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 3s 368ms/step - loss: 2.3172e-05 - accuracy: 1.0000 - val_loss: 3.4831 - val_accuracy: 0.6650\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 3s 337ms/step - loss: 1.3660e-05 - accuracy: 1.0000 - val_loss: 3.5691 - val_accuracy: 0.6550\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 1.0249e-05 - accuracy: 1.0000 - val_loss: 3.5767 - val_accuracy: 0.6700\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 1.5032e-05 - accuracy: 1.0000 - val_loss: 3.6121 - val_accuracy: 0.6700\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 3s 358ms/step - loss: 3.8074e-06 - accuracy: 1.0000 - val_loss: 3.6873 - val_accuracy: 0.6800\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 3s 359ms/step - loss: 5.0067e-06 - accuracy: 1.0000 - val_loss: 3.7457 - val_accuracy: 0.6800\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 3s 348ms/step - loss: 2.4163e-06 - accuracy: 1.0000 - val_loss: 3.8252 - val_accuracy: 0.6750\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 3s 357ms/step - loss: 2.7436e-06 - accuracy: 1.0000 - val_loss: 4.0279 - val_accuracy: 0.6650\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 366ms/step - loss: 2.5853e-06 - accuracy: 1.0000 - val_loss: 3.9892 - val_accuracy: 0.6700\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 3s 367ms/step - loss: 9.2293e-07 - accuracy: 1.0000 - val_loss: 4.0633 - val_accuracy: 0.6700\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 7.0501e-07 - accuracy: 1.0000 - val_loss: 4.0915 - val_accuracy: 0.6750\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 3s 371ms/step - loss: 5.6065e-07 - accuracy: 1.0000 - val_loss: 4.1834 - val_accuracy: 0.6750\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 2.6714e-07 - accuracy: 1.0000 - val_loss: 4.2790 - val_accuracy: 0.6800\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 3s 369ms/step - loss: 2.3562e-07 - accuracy: 1.0000 - val_loss: 4.2875 - val_accuracy: 0.6800\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 2.0256e-07 - accuracy: 1.0000 - val_loss: 4.3773 - val_accuracy: 0.6650\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 9.6392e-08 - accuracy: 1.0000 - val_loss: 4.4030 - val_accuracy: 0.6650\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 9.6229e-08 - accuracy: 1.0000 - val_loss: 4.5117 - val_accuracy: 0.6750\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 1.0477e-07 - accuracy: 1.0000 - val_loss: 4.6057 - val_accuracy: 0.6750\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 3.1665e-08 - accuracy: 1.0000 - val_loss: 4.7615 - val_accuracy: 0.6750\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 2.9683e-08 - accuracy: 1.0000 - val_loss: 4.8302 - val_accuracy: 0.6550\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 1.7714e-08 - accuracy: 1.0000 - val_loss: 4.8179 - val_accuracy: 0.6600\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 9.0963e-09 - accuracy: 1.0000 - val_loss: 4.9521 - val_accuracy: 0.6550\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 3s 335ms/step - loss: 3.1897e-07 - accuracy: 1.0000 - val_loss: 8.5262 - val_accuracy: 0.6000\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 3.1814 - accuracy: 0.8755 - val_loss: 4.3265 - val_accuracy: 0.6300\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 0.0223 - accuracy: 0.9961 - val_loss: 3.8572 - val_accuracy: 0.6600\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.0197 - val_accuracy: 0.6700\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.8293 - val_accuracy: 0.6550\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 0.0031 - accuracy: 0.9961 - val_loss: 4.5222 - val_accuracy: 0.6450\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 2.0754e-04 - accuracy: 1.0000 - val_loss: 4.3641 - val_accuracy: 0.6450\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 3s 326ms/step - loss: 4.1452e-05 - accuracy: 1.0000 - val_loss: 4.3145 - val_accuracy: 0.6400\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 3s 321ms/step - loss: 2.8867e-04 - accuracy: 1.0000 - val_loss: 4.1550 - val_accuracy: 0.6450\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 1.4203e-05 - accuracy: 1.0000 - val_loss: 4.1661 - val_accuracy: 0.6450\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 7.4670e-06 - accuracy: 1.0000 - val_loss: 4.1673 - val_accuracy: 0.6500\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 5.3662e-06 - accuracy: 1.0000 - val_loss: 4.1778 - val_accuracy: 0.6450\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 7.1266e-06 - accuracy: 1.0000 - val_loss: 4.1778 - val_accuracy: 0.6500\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 5.8333e-06 - accuracy: 1.0000 - val_loss: 4.1833 - val_accuracy: 0.6550\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 6.0975e-06 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.6650\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 1.9317e-06 - accuracy: 1.0000 - val_loss: 4.1876 - val_accuracy: 0.6600\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 2.2621e-06 - accuracy: 1.0000 - val_loss: 4.2258 - val_accuracy: 0.6550\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 1.2228e-06 - accuracy: 1.0000 - val_loss: 4.2495 - val_accuracy: 0.6600\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 1.7485e-06 - accuracy: 1.0000 - val_loss: 4.2765 - val_accuracy: 0.6600\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 6.2381e-07 - accuracy: 1.0000 - val_loss: 4.3030 - val_accuracy: 0.6600\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 5.9697e-07 - accuracy: 1.0000 - val_loss: 4.3495 - val_accuracy: 0.6550\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 3.2643e-07 - accuracy: 1.0000 - val_loss: 4.3970 - val_accuracy: 0.6600\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 2.0908e-07 - accuracy: 1.0000 - val_loss: 4.4401 - val_accuracy: 0.6600\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 3s 336ms/step - loss: 2.9942e-07 - accuracy: 1.0000 - val_loss: 4.5434 - val_accuracy: 0.6650\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 2.5182e-07 - accuracy: 1.0000 - val_loss: 4.6348 - val_accuracy: 0.6700\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 8.9527e-08 - accuracy: 1.0000 - val_loss: 4.6372 - val_accuracy: 0.6750\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 3s 316ms/step - loss: 8.1025e-08 - accuracy: 1.0000 - val_loss: 4.6749 - val_accuracy: 0.6750\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 7.6834e-08 - accuracy: 1.0000 - val_loss: 4.7233 - val_accuracy: 0.6850\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 3s 321ms/step - loss: 7.2292e-08 - accuracy: 1.0000 - val_loss: 4.8067 - val_accuracy: 0.6850\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 2.7940e-08 - accuracy: 1.0000 - val_loss: 4.9678 - val_accuracy: 0.6900\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 1.6994 - accuracy: 0.9375 - val_loss: 16.7191 - val_accuracy: 0.5500\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 3s 321ms/step - loss: 0.8624 - accuracy: 0.9478 - val_loss: 3.3502 - val_accuracy: 0.6600\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 3s 320ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.2505 - val_accuracy: 0.6850\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 2.3424e-04 - accuracy: 1.0000 - val_loss: 3.2539 - val_accuracy: 0.6850\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 5.1037e-04 - accuracy: 1.0000 - val_loss: 3.3051 - val_accuracy: 0.6800\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 3.8543e-04 - accuracy: 1.0000 - val_loss: 3.3330 - val_accuracy: 0.6750\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 3s 321ms/step - loss: 2.4225e-04 - accuracy: 1.0000 - val_loss: 3.3551 - val_accuracy: 0.6850\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 7.4820e-05 - accuracy: 1.0000 - val_loss: 3.3778 - val_accuracy: 0.6900\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 3s 321ms/step - loss: 1.0845e-04 - accuracy: 1.0000 - val_loss: 3.4533 - val_accuracy: 0.6800\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 3s 324ms/step - loss: 5.3886e-05 - accuracy: 1.0000 - val_loss: 3.5044 - val_accuracy: 0.6850\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 1.4216e-04 - accuracy: 1.0000 - val_loss: 3.7083 - val_accuracy: 0.6700\n",
      "Epoch 280/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 327ms/step - loss: 7.4432e-05 - accuracy: 1.0000 - val_loss: 3.7327 - val_accuracy: 0.6800\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 3.8852e-05 - accuracy: 1.0000 - val_loss: 3.7327 - val_accuracy: 0.6700\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 2.0086e-05 - accuracy: 1.0000 - val_loss: 3.7659 - val_accuracy: 0.6800\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 3s 327ms/step - loss: 1.3919e-05 - accuracy: 1.0000 - val_loss: 3.8544 - val_accuracy: 0.6900\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 9.9781e-06 - accuracy: 1.0000 - val_loss: 3.8708 - val_accuracy: 0.6950\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 3s 320ms/step - loss: 7.0108e-06 - accuracy: 1.0000 - val_loss: 3.9763 - val_accuracy: 0.6900\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 2.8954e-06 - accuracy: 1.0000 - val_loss: 3.9771 - val_accuracy: 0.6950\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 1.9604e-06 - accuracy: 1.0000 - val_loss: 4.0951 - val_accuracy: 0.6900\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 1.6698e-06 - accuracy: 1.0000 - val_loss: 4.1475 - val_accuracy: 0.6850\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 2.1929e-06 - accuracy: 1.0000 - val_loss: 4.0761 - val_accuracy: 0.7150\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 3s 336ms/step - loss: 8.3538e-07 - accuracy: 1.0000 - val_loss: 4.2136 - val_accuracy: 0.7150\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 5.0431e-07 - accuracy: 1.0000 - val_loss: 4.2836 - val_accuracy: 0.7100\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 2.2406e-07 - accuracy: 1.0000 - val_loss: 4.3366 - val_accuracy: 0.7100\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 1.6852e-07 - accuracy: 1.0000 - val_loss: 4.3897 - val_accuracy: 0.7100\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 2.1141e-07 - accuracy: 1.0000 - val_loss: 4.4523 - val_accuracy: 0.7200\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 1.2200e-07 - accuracy: 1.0000 - val_loss: 4.5474 - val_accuracy: 0.7150\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 6.9419e-08 - accuracy: 1.0000 - val_loss: 4.5474 - val_accuracy: 0.7200\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 6.5658e-08 - accuracy: 1.0000 - val_loss: 4.6528 - val_accuracy: 0.7200\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 2.7008e-08 - accuracy: 1.0000 - val_loss: 4.6843 - val_accuracy: 0.7200\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 1.7235e-08 - accuracy: 1.0000 - val_loss: 4.6846 - val_accuracy: 0.7200\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 1.3504e-08 - accuracy: 1.0000 - val_loss: 4.6709 - val_accuracy: 0.7200\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 1.6278e-08 - accuracy: 1.0000 - val_loss: 4.9615 - val_accuracy: 0.7100\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 5.1223e-09 - accuracy: 1.0000 - val_loss: 4.9595 - val_accuracy: 0.7200\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 8.3819e-09 - accuracy: 1.0000 - val_loss: 4.9476 - val_accuracy: 0.7200\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 5.0317 - val_accuracy: 0.7100\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 5.0832 - val_accuracy: 0.6900\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 2.3283e-09 - accuracy: 1.0000 - val_loss: 5.1647 - val_accuracy: 0.7050\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 1.3970e-09 - accuracy: 1.0000 - val_loss: 5.2964 - val_accuracy: 0.7000\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 4.6566e-10 - accuracy: 1.0000 - val_loss: 5.2588 - val_accuracy: 0.7050\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 4.7875e-10 - accuracy: 1.0000 - val_loss: 5.1358 - val_accuracy: 0.7100\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 4.6566e-10 - accuracy: 1.0000 - val_loss: 5.2000 - val_accuracy: 0.7000\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 4.6566e-10 - accuracy: 1.0000 - val_loss: 5.2710 - val_accuracy: 0.6950\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 3s 334ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2378 - val_accuracy: 0.6950\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 4.7875e-10 - accuracy: 1.0000 - val_loss: 5.6582 - val_accuracy: 0.6800\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 1.3970e-09 - accuracy: 1.0000 - val_loss: 5.6733 - val_accuracy: 0.6900\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4378 - val_accuracy: 0.6950\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5737 - val_accuracy: 0.7000\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5259 - val_accuracy: 0.6950\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 3s 322ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5261 - val_accuracy: 0.6950\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 3s 323ms/step - loss: 4.7875e-10 - accuracy: 1.0000 - val_loss: 5.4840 - val_accuracy: 0.6900\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 3s 325ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5017 - val_accuracy: 0.6900\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 3s 329ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5019 - val_accuracy: 0.6900\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 3s 361ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4973 - val_accuracy: 0.6900\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 3s 346ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.6170 - val_accuracy: 0.6850\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 3s 364ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.6069 - val_accuracy: 0.6850\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 3s 354ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4533 - val_accuracy: 0.6900\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 3s 331ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.7190 - val_accuracy: 0.6750\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.7022 - val_accuracy: 0.6750\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.6246 - val_accuracy: 0.6750\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.6200 - val_accuracy: 0.6750\n",
      "Epoch 330/1000\n",
      "5/8 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "#change the learning rate and the number of epochs\n",
    "history = model.fit(train_generator,validation_data=test_set,steps_per_epoch=8,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3123cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#save weights for future predictions\n",
    "model.save_weights('first_try.hs')\n",
    "\n",
    "#plot variation in loss and accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plot the loss\n",
    "plt.plot(history.history['loss'],label='train loss')\n",
    "plt.plot(history.history['val_loss'],label='val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "#plot the accuracy\n",
    "plt.plot(history.history['accuracy'],label='train acc')\n",
    "plt.plot(history.history['val_accuracy'],label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc7ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
